lines(levels[-1], log2(var1[-1]), type = "o", pch = 16, lty = 2)
legend("bottomleft", legend = c(expression(P[l]), expression(P[l] - P[l-1])),
lty = c(1, 2), pch = 16, cex=0.8, bty="n")
# Plot 2: log2(|mean|) vs level
plot(levels, log2(abs(del2)), type = "o", pch = 16, lty = 1,
xlab = "Level l", ylab = expression(log[2]~"|mean|"),
ylim = range(c(log2(abs(del1[-1])), log2(abs(del2)))))
lines(levels[-1], log2(abs(del1[-1])), type = "o", pch = 16, lty = 2)
legend("bottomleft", legend = c(expression(P[l]), expression(P[l] - P[l-1])),
lty = c(1, 2), pch = 16, cex=0.8, bty="n")
if (nvert == 3) {
# Plot 3: Consistency check
plot(levels[-1], chk1[-1], type = "o", pch = 16, lty = 2,
xlab = "Level l", ylab = "Consistency Check")
# Plot 4: Kurtosis
plot(levels[-1], kur1[-1], type = "o", pch = 16, lty = 2,
xlab = "Level l", ylab = "Kurtosis")
}
if (nvert == 1) {
# If nvert=1, the complexity plots go on a new figure
dev.new()
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1) + 0.1)
}
# --- Part 2: MLMC Complexity Tests ---
cat("\n--- MLMC Complexity Tests ---\n")
set.seed(42) # Reset seed for reproducibility
# We need to store Nl for each eps. A list is a flexible way to do this.
Nls_list <- list()
mlmc_cost <- c()
std_cost  <- c()
for (i in 1:length(Eps)) {
eps <- Eps[i]
cat(sprintf("eps = %f\n", eps))
# Here, gamma is specified by M, the cost factor per level.
gamma_cost <- log2(M)
# We create a simplified `mlmc_l` for the main `mlmc` function,
# which only needs the first two moments of the difference.
mlmc_l_simple <- function(l, N) {
res <- mlmc_fn(l, N)
return(res$sum1[1:2]) # Return sum(Y) and sum(Y^2)
}
mlmc_results <- mlmc(N0, eps, mlmc_l_simple, alpha, beta, gamma_cost)
Nl <- mlmc_results$Nl
l <- length(Nl) - 1
Nls_list[[i]] <- Nl
mlmc_cost[i]  <- sum(Nl * M^(0:l))
std_cost[i]   <- (var2[l+1] / (eps^2)) * M^l
cat(sprintf("  mlmc_cost = %.2e, std_cost = %.2e, savings = %.2f\n",
mlmc_cost[i], std_cost[i], std_cost[i] / mlmc_cost[i]))
}
# Convert Nls list to a matrix for plotting, padding with NA
max_levels <- max(sapply(Nls_list, length))
Nls_mat <- sapply(Nls_list, function(x) c(x, rep(NA, max_levels - length(x))))
# --- Plotting Complexity Results ---
# Define colors and point characters for the plot
colors <- rainbow(length(Eps))
pchs <- 1:length(Eps)
# Plot 5: N_l vs level
matplot(0:(max_levels - 1), Nls_mat, type = "b", log = "y",
xlab = "Level l", ylab = expression(N[l]),
col = colors, pch = pchs, lty = 1)
legend("topright", legend = as.character(Eps), title = expression(epsilon),col = rainbow(length(Eps)), pch = 1:length(Eps), lty=1, cex=0.8, bty="n")
# Plot 6: Cost vs epsilon
plot(Eps, Eps^2 * mlmc_cost, type = "o", pch = 17, lty = 1, log = "xy",col="red",
xlab = expression(paste("Accuracy ", epsilon)),
ylab = expression(paste(epsilon^2, " Cost")),
ylim = range(c(Eps^2 * mlmc_cost, Eps^2 * std_cost)))
lines(Eps, Eps^2 * std_cost, type = "o", pch = 15, lty = 2,col="blue")
legend("topright", legend = c("Std MC", "MLMC"), lty = c(2, 1), pch = c(15,17), cex=0.8, bty="n",col=c("blue", "red"))
title("MLMC with Tamed Euler-Maruyama", line = -1.5, outer = TRUE)
}
#' Main driver function for GBM option pricing example
#'
#' @description
#' This function sets up and runs the MLMC tests for pricing European call
#' and digital call options under a Geometric Brownian Motion model.
#' It defines the necessary parameters and the level `l` estimator function `gbm_l`.
#'
#' @return NULL. Called for its side effects of running simulations and
#'   producing plots.
#'
# --- Problem Parameters ---
# These will be available to the nested function `gbm_l` via lexical scoping,
# which is the preferred R alternative to using global variables.
S0     <- 1    # initial asset value
K      <- 100    # strike
T_mat  <- 10      # maturity (T is a reserved name in R for TRUE)
r      <- 0.05   # risk-free interest rate
sig    <- 0.2    # volatility
option <- NULL   # will be set to 1 (call) or 2 (digital)
# --- Level `l` estimator function for GBM ---
# This function is defined inside `gbm` to get access to the parameters above.
# This is the `mlmc_fn` passed to `mlmc_test`.
gbm_l <- function(l, N) {
M <- 2
nf <- M^l
nc <- nf / M
hf <- T_mat / nf
hc <- T_mat / nc
sum1 <- rep(0, 4)
sum2 <- rep(0, 2)
# Process in chunks to manage memory
chunk_size <- 10000
for (N1 in seq(1, N, by = chunk_size)) {
N2 <- min(chunk_size, N - N1 + 1)
Sf <- rep(S0, N2)
Sc <- Sf
Pc <- rep(0, N2)
#########################
##  KEY PORTION START  ##
#########################
if (l == 0) {
dWf <- sqrt(hf) * rnorm(N2)
Sf  <- Sf + (- Sf**3 + 10*Sf) / (1 + abs(- Sf**3 + 10*Sf))* hf + Sf * 0.5 * dWf # tamed Euler-Maruyama step
} else {
for (n in 1:nc) {
dWc <- rep(0, N2)
for (m in 1:M) {
dWf <- sqrt(hf) * rnorm(N2)
dWc <- dWc + dWf
Sf  <- Sf + (- Sf**3 + 10*Sf) / (1 + abs(- Sf**3 + 10*Sf))* hf + Sf * 0.5 * dWf
}
Sc <- Sc + (- Sc**3 + 10*Sc) / (1 + abs(- Sc**3 + 10*Sc))* hc + Sc * 0.5 * dWc
}
}
Pf <- Sf
Pc <- Sc
# if (option == 1) { # European call
#   Pf <- exp(-r * T_mat) * pmax(0, Sf - K)
#   if (l > 0) {
#     Pc <- exp(-r * T_mat) * pmax(0, Sc - K)
#   }
# } else if (option == 2) { # Digital call
#   Pf <- exp(-r * T_mat) * 10 * 0.5 * (1 + sign(Sf - K))
#   if (l > 0) {
#     Pc <- exp(-r * T_mat) * 10 * 0.5 * (1 + sign(Sc - K))
#   }
# }
#
#######################
##  KEY PORTION END  ##
#######################
diff <- Pf - Pc
sum1[1] <- sum1[1] + sum(diff)
sum1[2] <- sum1[2] + sum(diff^2)
sum1[3] <- sum1[3] + sum(diff^3)
sum1[4] <- sum1[4] + sum(diff^4)
sum2[1] <- sum2[1] + sum(Pf)
sum2[2] <- sum2[2] + sum(Pf^2)
}
return(list(sum1 = sum1, sum2 = sum2))
} # end of gbm_l definition
# --- MLMC Test Parameters ---
nvert <- 3        # Plotting option (1 for slides, 2 for papers, 3 for full set)
M     <- 2        # Refinement factor
N     <- 100000   # Samples for convergence tests
L_max <- 8        # Max level for convergence tests
N0    <- 1000     # Initial samples for MLMC
Eps   <- c(0.005, 0.01, 0.02, 0.05, 0.1) # Desired accuracies
# N0    <- 100     # Initial samples for MLMC
# Eps   <- c(0.0001, 0.0002, 0.0005, 0.001, 0.002) # Desired accuracies
# --- Run tests for European call option ---
cat("\n====================================\n")
cat("Running tests for European Call Option\n")
cat("====================================\n")
option <- 1
mlmc_test(gbm_l, M, N, L_max, N0, Eps, nvert)
#' Multi-Level Monte Carlo estimation
#'
#' @description
#' This function performs a multi-level Monte Carlo estimation to achieve a
#' specified accuracy.
#'
#' @param N0 Initial number of samples to use on the first few levels.
#' @param eps Desired accuracy (root mean square error).
#' @param mlmc_l A function for the level `l` estimator. It must be a function
#'   that takes two arguments: `l` (level) and `N` (number of paths), and
#'   returns a numeric vector where `sums[1]` is `sum(Y)` and `sums[2]` is
#'   `sum(Y^2)`. `Y` are IID samples with expected value `E[P_0]` on level 0,
#'   and `E[P_l - P_{l-1}]` on level `l > 0`.
#' @param alpha_0 The weak error rate, where error is $O(2^{-\alpha \cdot l})$.
#'   If non-positive, it will be estimated.
#' @param beta_0 The variance rate, where variance is $O(2^{-\beta \cdot l})$.
#'   If non-positive, it will be estimated.
#' @param gamma The sample cost rate, where cost is $O(2^{\gamma \cdot l})$.
#'
#' @return A list containing:
#'   - `P`: The final MLMC estimated value.
#'   - `Nl`: A vector with the number of samples used at each level.
#'
mlmc <- function(N0, eps, mlmc_l, alpha_0, beta_0, gamma) {
alpha <- max(0, alpha_0)
beta  <- max(0, beta_0)
L     <- 2
Nl    <- rep(0, 3) # Nl for levels 0, 1, 2
suml  <- matrix(0, nrow = 2, ncol = 3)
dNl   <- rep(N0, 3)
while (sum(dNl) > 0) {
# --- Update sample sums ---
for (l in 0:L) {
if (dNl[l + 1] > 0) {
sums <- mlmc_l(l, dNl[l + 1])
Nl[l + 1]   <- Nl[l + 1] + dNl[l + 1]
suml[1, l + 1] <- suml[1, l + 1] + sums[1]
suml[2, l + 1] <- suml[2, l + 1] + sums[2]
}
}
# --- Compute absolute average and variance ---
ml <- abs(suml[1, ] / Nl)
Vl <- pmax(0, suml[2, ] / Nl - ml^2)
if (L + 1 > 2) {
for (l in 3:(L + 1)) {
# R indexing for Level l is l.
ml[l] <- max(ml[l], 0.5 * ml[l - 1] / 2^alpha)
Vl[l] <- max(Vl[l], 0.5 * Vl[l - 1] / 2^beta)
}
}
# --- Use linear regression to estimate alpha, beta if not given ---
if (alpha_0 <= 0 && L >= 2) {
# The model is log2(m_l) ~ c - alpha*l
levels_reg <- 1:L
fit <- lm(log2(ml[2:(L + 1)]) ~ levels_reg)
# coef(fit)[2] is the slope, which corresponds to -alpha
alpha <- max(0.5, -coef(fit)[2])
}
if (beta_0 <= 0 && L >= 2) {
levels_reg <- 1:L
fit <- lm(log2(Vl[2:(L + 1)]) ~ levels_reg)
beta <- max(0.5, -coef(fit)[2])
}
# --- Set optimal number of additional samples ---
Cl <- 2^(gamma * (0:L))
Ns <- ceiling(2 * sqrt(Vl / Cl) * sum(sqrt(Vl * Cl)) / eps^2)
dNl <- pmax(0, Ns - Nl)
# --- If (almost) converged, check if a new level is required ---
if (sum(dNl > 0.01 * Nl) == 0) {
# rem = max(ml(L+1+range).*2.^(alpha*range)) / (2^alpha - 1);
rem <- ml[L + 1] / (2^alpha - 1)
if (rem > eps / sqrt(2)) {
L <- L + 1
# Grow vectors/matrices dynamically. Acceptable since this happens infrequently.
Vl   <- c(Vl, Vl[L] / 2^beta)
Nl   <- c(Nl, 0)
# We only use the first two rows of suml, so just expand its columns
suml <- cbind(suml, c(0, 0))
Cl <- 2^(gamma * (0:L))
Ns <- ceiling(2 * sqrt(Vl / Cl) * sum(sqrt(Vl * Cl)) / eps^2)
dNl <- pmax(0, Ns - Nl)
}
}
}
# --- Finally, evaluate multilevel estimator ---
P <- sum(suml[1, ] / Nl)
return(list(P = P, Nl = Nl))
}
#' Multilevel Monte Carlo Test Routine
#'
#' @description
#' This function performs convergence and complexity tests for the MLMC algorithm.
#'
#' @param mlmc_fn A low-level function for level `l` estimation. It must take `(l, N)`
#'   and return a list of two vectors: `sum1` and `sum2`.
#'   `sum1` contains sums of `(Pf-Pc)`, `(Pf-Pc)^2`, `(Pf-Pc)^3`, `(Pf-Pc)^4`.
#'   `sum2` contains sums of `Pf` and `Pf^2`.
#' @param M Refinement cost factor (typically 2). Corresponds to $2^\gamma$ in MLMC theory.
#' @param N Number of samples for convergence tests.
#' @param L_max Number of levels for convergence tests.
#' @param N0 Initial number of samples for MLMC calculations.
#' @param Eps A vector of desired accuracies for MLMC calculations.
#' @param nvert Plotting layout option (1: 1x2, 2: 2x2, 3: 3x2 plots).
#'
#' @return NULL. This function is called for its side effect of producing plots.
#'
mlmc_test <- function(mlmc_fn, M, N, L_max, N0, Eps, nvert) {
# --- Part 1: Convergence Tests ---
cat("\n--- MLMC Convergence Tests ---\n")
set.seed(123)
del1 <- c()
del2 <- c()
var1 <- c()
var2 <- c()
kur1 <- c()
chk1 <- c()
cost <- c()
levels <- 0:L_max
for (l in levels) {
cat(sprintf("l = %d\n", l))
start_time <- proc.time()
res <- mlmc_fn(l, N)
cost <- c(cost, (proc.time() - start_time)[[3]])
sum1 <- res$sum1 / N
sum2 <- res$sum2 / N
kurt <- (sum1[4] - 4*sum1[3]*sum1[1] + 6*sum1[2]*sum1[1]^2 - 3*sum1[1]^4) /
(sum1[2] - sum1[1]^2)^2
del1 <- c(del1, sum1[1])
del2 <- c(del2, sum2[1])
var1 <- c(var1, sum1[2] - sum1[1]^2)
var2 <- c(var2, sum2[2] - sum2[1]^2)
var2 <- pmax(var2, 1e-12) # Fix for cases with var=0
kur1 <- c(kur1, kurt)
if (l == 0) {
check <- 0
} else {
# R uses 1-based indexing, so Level l corresponds to index l+1
check <- abs(del1[l + 1] + del2[l] - del2[l + 1]) /
(3.0 * (sqrt(var1[l + 1]) + sqrt(var2[l]) + sqrt(var2[l + 1])) / sqrt(N))
}
chk1 <- c(chk1, check)
}
# --- Use linear regression to estimate alpha, beta, and gamma ---
range <- max(2, floor(0.4 * length(levels))):length(levels)
cat("\nEstimates of key MLMC Theorem parameters based on linear regression:\n")
# MATLAB's polyfit(x,y,1) for slope: pa(1)
# R's lm(y ~ x) for slope: coef(fit)[2]
fit_a <- lm(log2(abs(del1[range])) ~ levels[range])
alpha <- -coef(fit_a)[2]
cat(sprintf("alpha = %f  (exponent for MLMC weak convergence)\n", alpha))
fit_b <- lm(log2(var1[range]) ~ levels[range])
beta <- -coef(fit_b)[2]
cat(sprintf("beta  = %f  (exponent for MLMC variance)\n", beta))
gamma <- log2(cost[length(cost)] / cost[length(cost) - 1])
cat(sprintf("gamma = %f  (exponent for MLMC cost)\n\n", gamma))
if (max(chk1) > 1) {
cat(sprintf("WARNING: maximum consistency error = %f\n", max(chk1)))
cat("indicates identity E[Pf-Pc] = E[Pf] - E[Pc] not satisfied\n\n")
}
if (kur1[length(kur1)] > 100) {
cat(sprintf("WARNING: kurtosis on finest level = %f\n", kur1[length(kur1)]))
cat("indicates MLMC correction dominated by a few rare paths\n\n")
}
# --- Plotting Figures ---
# Setup plotting device for the first set of plots
# In R, we create a new device, equivalent to `figure` in MATLAB
# dev.new()
# Set plot layout (nvert rows, 2 columns)
par(mfrow = c(nvert, 2), mar = c(4, 4, 2, 1) + 0.1) # mar sets margins
cat("layer", log2(var2), "\n")
cat("gap ")
for (a in var1[-1]){
cat(log2(a),",")
}
# Plot 1: log2(variance) vs level
plot(levels, log2(var2), type = "o", pch = 16, lty = 1,
xlab = "Level l", ylab = expression(log[2]~variance),
ylim = range(c(log2(var1[-1]), log2(var2))))
lines(levels[-1], log2(var1[-1]), type = "o", pch = 16, lty = 2)
legend("bottomleft", legend = c(expression(P[l]), expression(P[l] - P[l-1])),
lty = c(1, 2), pch = 16, cex=0.8, bty="n")
# Plot 2: log2(|mean|) vs level
plot(levels, log2(abs(del2)), type = "o", pch = 16, lty = 1,
xlab = "Level l", ylab = expression(log[2]~"|mean|"),
ylim = range(c(log2(abs(del1[-1])), log2(abs(del2)))))
lines(levels[-1], log2(abs(del1[-1])), type = "o", pch = 16, lty = 2)
legend("bottomleft", legend = c(expression(P[l]), expression(P[l] - P[l-1])),
lty = c(1, 2), pch = 16, cex=0.8, bty="n")
if (nvert == 3) {
# Plot 3: Consistency check
plot(levels[-1], chk1[-1], type = "o", pch = 16, lty = 2,
xlab = "Level l", ylab = "Consistency Check")
# Plot 4: Kurtosis
plot(levels[-1], kur1[-1], type = "o", pch = 16, lty = 2,
xlab = "Level l", ylab = "Kurtosis")
}
if (nvert == 1) {
# If nvert=1, the complexity plots go on a new figure
dev.new()
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1) + 0.1)
}
# --- Part 2: MLMC Complexity Tests ---
cat("\n--- MLMC Complexity Tests ---\n")
set.seed(42) # Reset seed for reproducibility
# We need to store Nl for each eps. A list is a flexible way to do this.
Nls_list <- list()
mlmc_cost <- c()
std_cost  <- c()
for (i in 1:length(Eps)) {
eps <- Eps[i]
cat(sprintf("eps = %f\n", eps))
# Here, gamma is specified by M, the cost factor per level.
gamma_cost <- log2(M)
# We create a simplified `mlmc_l` for the main `mlmc` function,
# which only needs the first two moments of the difference.
mlmc_l_simple <- function(l, N) {
res <- mlmc_fn(l, N)
return(res$sum1[1:2]) # Return sum(Y) and sum(Y^2)
}
mlmc_results <- mlmc(N0, eps, mlmc_l_simple, alpha, beta, gamma_cost)
Nl <- mlmc_results$Nl
l <- length(Nl) - 1
Nls_list[[i]] <- Nl
mlmc_cost[i]  <- sum(Nl * M^(0:l))
std_cost[i]   <- (var2[l+1] / (eps^2)) * M^l
cat(sprintf("  mlmc_cost = %.2e, std_cost = %.2e, savings = %.2f\n",
mlmc_cost[i], std_cost[i], std_cost[i] / mlmc_cost[i]))
}
# Convert Nls list to a matrix for plotting, padding with NA
max_levels <- max(sapply(Nls_list, length))
Nls_mat <- sapply(Nls_list, function(x) c(x, rep(NA, max_levels - length(x))))
# --- Plotting Complexity Results ---
# Define colors and point characters for the plot
colors <- rainbow(length(Eps))
pchs <- 1:length(Eps)
# Plot 5: N_l vs level
matplot(0:(max_levels - 1), Nls_mat, type = "b", log = "y",
xlab = "Level l", ylab = expression(N[l]),
col = colors, pch = pchs, lty = 1)
legend("topright", legend = as.character(Eps), title = expression(epsilon),col = rainbow(length(Eps)), pch = 1:length(Eps), lty=1, cex=0.8, bty="n")
# Plot 6: Cost vs epsilon
plot(Eps, Eps^2 * mlmc_cost, type = "o", pch = 17, lty = 1, log = "xy",col="red",
xlab = expression(paste("Accuracy ", epsilon)),
ylab = expression(paste(epsilon^2, " Cost")),
ylim = range(c(Eps^2 * mlmc_cost, Eps^2 * std_cost)))
lines(Eps, Eps^2 * std_cost, type = "o", pch = 15, lty = 2,col="blue")
legend("topright", legend = c("Std MC", "MLMC"), lty = c(2, 1), pch = c(15,17), cex=0.8, bty="n",col=c("blue", "red"))
title("MLMC with Tamed Euler-Maruyama", line = -1.5, outer = TRUE)
}
#' Main driver function for GBM option pricing example
#'
#' @description
#' This function sets up and runs the MLMC tests for pricing European call
#' and digital call options under a Geometric Brownian Motion model.
#' It defines the necessary parameters and the level `l` estimator function `gbm_l`.
#'
#' @return NULL. Called for its side effects of running simulations and
#'   producing plots.
#'
# --- Problem Parameters ---
# These will be available to the nested function `gbm_l` via lexical scoping,
# which is the preferred R alternative to using global variables.
S0     <- 1    # initial asset value
K      <- 100    # strike
T_mat  <- 10      # maturity (T is a reserved name in R for TRUE)
r      <- 0.05   # risk-free interest rate
sig    <- 0.2    # volatility
option <- NULL   # will be set to 1 (call) or 2 (digital)
# --- Level `l` estimator function for GBM ---
# This function is defined inside `gbm` to get access to the parameters above.
# This is the `mlmc_fn` passed to `mlmc_test`.
gbm_l <- function(l, N) {
M <- 2
nf <- M^l
nc <- nf / M
hf <- T_mat / nf
hc <- T_mat / nc
sum1 <- rep(0, 4)
sum2 <- rep(0, 2)
# Process in chunks to manage memory
chunk_size <- 10000
for (N1 in seq(1, N, by = chunk_size)) {
N2 <- min(chunk_size, N - N1 + 1)
Sf <- rep(S0, N2)
Sc <- Sf
Pc <- rep(0, N2)
#########################
##  KEY PORTION START  ##
#########################
if (l == 0) {
dWf <- sqrt(hf) * rnorm(N2)
Sf  <- Sf + (- Sf**3 + 10*Sf) / (1 + abs(- Sf**3 + 10*Sf))* hf + Sf * 0.5 * dWf # tamed Euler-Maruyama step
} else {
for (n in 1:nc) {
dWc <- rep(0, N2)
for (m in 1:M) {
dWf <- sqrt(hf) * rnorm(N2)
dWc <- dWc + dWf
Sf  <- Sf + (- Sf**3 + 10*Sf) / (1 + abs(- Sf**3 + 10*Sf))* hf + Sf * 0.5 * dWf
}
Sc <- Sc + (- Sc**3 + 10*Sc) / (1 + abs(- Sc**3 + 10*Sc))* hc + Sc * 0.5 * dWc
}
}
Pf <- Sf
Pc <- Sc
# if (option == 1) { # European call
#   Pf <- exp(-r * T_mat) * pmax(0, Sf - K)
#   if (l > 0) {
#     Pc <- exp(-r * T_mat) * pmax(0, Sc - K)
#   }
# } else if (option == 2) { # Digital call
#   Pf <- exp(-r * T_mat) * 10 * 0.5 * (1 + sign(Sf - K))
#   if (l > 0) {
#     Pc <- exp(-r * T_mat) * 10 * 0.5 * (1 + sign(Sc - K))
#   }
# }
#
#######################
##  KEY PORTION END  ##
#######################
diff <- Pf - Pc
sum1[1] <- sum1[1] + sum(diff)
sum1[2] <- sum1[2] + sum(diff^2)
sum1[3] <- sum1[3] + sum(diff^3)
sum1[4] <- sum1[4] + sum(diff^4)
sum2[1] <- sum2[1] + sum(Pf)
sum2[2] <- sum2[2] + sum(Pf^2)
}
return(list(sum1 = sum1, sum2 = sum2))
} # end of gbm_l definition
# --- MLMC Test Parameters ---
nvert <- 3        # Plotting option (1 for slides, 2 for papers, 3 for full set)
M     <- 2        # Refinement factor
N     <- 100000   # Samples for convergence tests
L_max <- 5        # Max level for convergence tests
N0    <- 1000     # Initial samples for MLMC
Eps   <- c(0.005, 0.01, 0.02, 0.05, 0.1) # Desired accuracies
# N0    <- 100     # Initial samples for MLMC
# Eps   <- c(0.0001, 0.0002, 0.0005, 0.001, 0.002) # Desired accuracies
# --- Run tests for European call option ---
cat("\n====================================\n")
cat("Running tests for European Call Option\n")
cat("====================================\n")
option <- 1
mlmc_test(gbm_l, M, N, L_max, N0, Eps, nvert)
