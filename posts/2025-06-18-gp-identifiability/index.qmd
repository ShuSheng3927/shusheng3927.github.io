---
title: "Identifiability Issues of Gaussian Processes"
description: "Describe the consistency and identifiability of Matérn GPs."
date: "18 June 2025"
bibliography: references.bib
categories:
  - Gaussian Process
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

## Introduction

Gaussian Processes (GPs) are central to spatial statistics and nonparametric modeling, offering a principled way to model spatial dependence. The **Matérn kernel**, in particular, provides a flexible class of covariance functions that control both the range and smoothness of spatial correlation.

However, the identifiability of GP parameters is an important issue sometimes overlooked in practice. Here, we will explore the existing literature on the consistency and identifiability of Matérn GP parameters. 

## 1. The Matérn Kernel and Parameters

The Matérn covariance function is defined as:

$$
k_\nu(h) = \sigma^2 \cdot \frac{2^{1 - \nu}}{\Gamma(\nu)} \left( \frac{h}{l} \right)^\nu K_\nu\left( \frac{h}{l} \right)
$$

where:

* $\sigma^2$: kernel variance
* $l$:lengthscale
* $\nu$: smoothness (higher $\nu$ implies smoother sample paths)
* $h$: distance
* $K_\nu$: modified Bessel function of the second kind

Furthermore, we can consider the Fourier transform of the above covariance function and obtain the Matérn spectral density function, given by 

$$
S(u) = C \frac{\sigma^2 l^{-2\nu}}{(l^{-2} + u^2)^{\nu + d/2}}
$$

for some constant $C > 0$ where $d$ is the dimension of the stochastic process. 

## 2. Asymptotic Frameworks

When considering the asymptotic parameter estiamtions, we often let the number of observations go to infinity. In the context of spatial statistics, there are two cases of this limiting behavior: fixed-domain and increasing-domain. Futhermore, it is standard in the literature to assume that the underlying spatial field is fixed throughout the sampling process (i.e. we can always making observations about the same spatial field sample). 

### Fixed-Domain Asymptotics

Also called **infill asymptotics**. The domain of interest remains fixed (e.g., $[0,1]^d$), while the number of observations increases within that domain.

* Common in geostatistics when the spatial extent is constrained (e.g., environmental sampling).
* The GP becomes more densely sampled, but still only a single realization is observed.

### Increasing-Domain Asymptotics

The spatial domain grows (e.g., from $[0,1]^2$ to $[0, L]^2$), while maintaining fixed sampling density.

* Appropriate in large-scale spatial surveys (e.g., national or continental datasets).
* Provides more information about the long-range behavior of the process.

## 3. Identifiability and Equivalence of Gaussian Measures

We will restrict ourselves to the fixed-domain asymptotic setting and examine the identifiability issue under this regime. The key theoretical tool we use is the equivalence between probability measures. 

Consider two probability measures $P_1, P_2$ defined on the same probability space $(\Omega, \mathcal{F})$. We say the measure $P_1$ is **absolutely continuous** w.r.t. $P_2$ if $P_2(A) = 0 \implies P_1(A) = 0$ for all $A \in \mathcal{F}$, denoted by $P_1 \ll P_2$. We also say $P_1$ is **equivalent** to $P_2$ if we have $P_1 \ll P_2$ and $P_1 \gg P_2$. 

The statistical implications of equivalent measures are: (1) we cannot claim with probability one samples from any of the equivalent measure are from which of the measures, (2) if the equivalent measures is a family parameterised by $\theta \in \Theta$, we cannot consistently estimate all $\theta$, (3) for equivalent measures, the prediction of a new random variable condition on the same list of random variables agree as the list increases to infinity. Thus, roughly speaking, if the measures are equivalent, we cannot estimate parameters consistently, yet they should yield the same predictions. 

We denote $P_{\sigma, l}$ to be the Gaussian measure for a Matérn GP of smoothness parameter $\nu$ with variance $\sigma^2$ and lengthscale $l$. It turns out that, two such measures $P_{\sigma_1, l_1}, P_{\sigma_2, l_2}$ are equivalent if and only if $\sigma_1^2 / l_1^{2\nu} = \sigma_2^2 / l_2^{2\nu}$ (@zhang2004inconsistent, @stein2004equivalence). 

This implies that we cannot consistently estimate $\sigma$ or $l$, yet we can consistently estimate the microergodic parameter $\sigma_2^2 / l^{2\nu}$. Additionally, despite the lack of identifiabilities for some parameters, interpolation and predictions remains feasible. 

The result above is obtained by a sufficient condition of Gaussian measure equivalence due to @stein1999interpolation, which poses a condition based on the spectral densities of the two measures. The result of @zhang2004inconsistent was established by checking this condition. It should not be too surprising then to accept the critical importance of $\sigma_2^2 / l^{2\nu}$ by looking at its role in the spectral density of a Matérn kernel. 

![Simulation results on the estimation of parameters of a Matern kernel with increasing number of observations.](Matern_same_no_nugget.png)

## 4. Nugget

The observation noise of a spatial model is often known as the nugget in the literature. The result above does not assume the observations are made with noise. The recent work of @tang2021identifiability extends many of the previous consistency and identifiability results to the case where nuggets occur. The qualitative behaviour remains under this more general setting, yet the asymptotic normality of the maximum likelihood estimator of the microergodic parameter has a different convergence rate: for observation number $n$, without the nugget the rate is $n^{1/2}$ and with the nugget the rate is $n^{1/(2+4\nu / d)}$. 


## 5. Visualizing the Likelihood Surface

We now visualize likelihoods under noiseless and noisy observations. Both surfaces indicates the non-identifiability of $\sigma$ and $l$. 

```{r, echo=FALSE}
# R code to visualize likelihood surfaces for Matérn GP
library(fields); library(MASS)
library(mvtnorm)

# 1. Define covariance function (no nugget)
cov_mat <- function(x, rho, sigma2, nu=0.5) {
  d <- rdist(x)
  sigma2 * exp(-d / rho)
}

# Sample spatial locations
set.seed(42)
x <- matrix(runif(100), ncol=1)

# Simulate noiseless field
Sigma_true <- cov_mat(x, rho=0.2, sigma2=1)
y0 <- mvrnorm(1, mu=rep(0, nrow(x)), Sigma_true)

# Simulate noisy data
tau2_true <- 0.1
y1 <- y0 + rnorm(length(y0), sd=sqrt(tau2_true))

# Likelihood grid
rho_grid <- seq(0.05, 1, length=100)
sigma_grid <- seq(0.2, 2, length=100)
logLik0 <- logLik1 <- matrix(NA, 100, 100)

for (i in 1:100) {
  for (j in 1:100) {
    S <- cov_mat(x, rho_grid[i], sigma_grid[j])
    logLik0[i,j] <- dmvnorm(y0, sigma=S, log=TRUE)
    logLik1[i,j] <- dmvnorm(y1, sigma=S + diag(tau2_true, nrow(x)), log=TRUE)
  }
}


library(ggplot2)
library(viridis)
library(cowplot)

# Prepare data
grid <- expand.grid(rho = rho_grid, sigma2 = sigma_grid)
df0 <- cbind(grid, logLik = as.vector(logLik0))
df1 <- cbind(grid, logLik = as.vector(logLik1))

# Plot 1 — No Noise
p1 <- ggplot(df0, aes(x = rho, y = sigma2, z = logLik)) +
  geom_raster(aes(fill = logLik)) +
  geom_contour(color = "grey", lwd=0.8) +
  scale_fill_viridis(option = "inferno", name = "log-Lik") +
  labs(title = "No Noise", x = "Lengthscale", y = "Variance") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid = element_blank(),         # Remove grid lines
    axis.ticks.length = unit(0, "pt"),    # No extra tick length
    panel.spacing = unit(0, "pt"),        # No spacing in facets
    axis.text = element_text(margin = margin(0, 0, 0, 0)), # Tight axis labels
    plot.margin = margin(2, 2, 2, 2)       # Minimal outer margin
  )

# Plot 2 — With Noise
p2 <- ggplot(df1, aes(x = rho, y = sigma2, z = logLik)) +
  geom_raster(aes(fill = logLik)) +
  geom_contour(color = "grey", lwd=0.8) +
  scale_fill_viridis(option = "inferno", name = "log-Lik") +
  labs(title = "With Noise", x = "Lengthscale", y = "Variance") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid = element_blank(),         # Remove grid lines
    axis.ticks.length = unit(0, "pt"),    # No extra tick length
    panel.spacing = unit(0, "pt"),        # No spacing in facets
    axis.text = element_text(margin = margin(0, 0, 0, 0)), # Tight axis labels
    plot.margin = margin(2, 2, 2, 2)       # Minimal outer margin
  ) 
print(p1)
print(p2)

```

## 6. Summary

| Scenario                | Identifiable Parameters          | Key Results                |
| ----------------------- | -------------------------------- | -------------------------- |
| Noiseless, fixed-domain | Only $\sigma^2/l^{2\nu}$      | @zhang2004inconsistent            |
| Noisy, fixed-domain     | $\sigma^2/l^{2\nu}$, $\tau^2$ | @tang2021identifiability        |
| Increasing-domain       | All parameters                   | Standard asymptotics apply |

As a side remark, we are always working in the setting where the spatial field is fixed throughout the sampling. The following simulation result indicates that we may have identifiable parameters for different spatial field samples. 

![Simulation results on the estimation of parameters of a Matern kernel with increasing number of observations with different spatial field each run.](Matern_different_nugget.png)