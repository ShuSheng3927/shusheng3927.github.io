<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rui-Yang Zhang">
<meta name="dcterms.date" content="2025-02-07">
<meta name="description" content="Computations and derivations of the expected information gain utility function of active learning when the surrogate model is a conjugate Gaussian process.">

<title>Rui-Yang Zhang - Expected Information Gain with Gaussian Process Surrogate Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../rui.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../rui.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Rui-Yang Zhang</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html" rel="" target="">
 <span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes.html" rel="" target="">
 <span class="menu-text">Notes &amp; Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resources.html" rel="" target="">
 <span class="menu-text">Resources</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Expected Information Gain with Gaussian Process Surrogate Models</h1>
                  <div>
        <div class="description">
          Computations and derivations of the expected information gain utility function of active learning when the surrogate model is a conjugate Gaussian process.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Active Learning</div>
                <div class="quarto-category">Gaussian Process</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Rui-Yang Zhang </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 7, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introducing-expected-information-gain" id="toc-introducing-expected-information-gain" class="nav-link active" data-scroll-target="#introducing-expected-information-gain">Introducing Expected Information Gain</a></li>
  <li><a href="#eig-reformualtion---a-first-attempt" id="toc-eig-reformualtion---a-first-attempt" class="nav-link" data-scroll-target="#eig-reformualtion---a-first-attempt">EIG Reformualtion - a first attempt</a></li>
  <li><a href="#eig-reformualtion---a-second-attempt" id="toc-eig-reformualtion---a-second-attempt" class="nav-link" data-scroll-target="#eig-reformualtion---a-second-attempt">EIG Reformualtion - a second attempt</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Dennis_Lindley.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Dennis Lindley; <span class="citation" data-cites="lindley1956measure">Lindley (<a href="#ref-lindley1956measure" role="doc-biblioref">1956</a>)</span></figcaption>
</figure>
</div>
<section id="introducing-expected-information-gain" class="level3">
<h3 class="anchored" data-anchor-id="introducing-expected-information-gain">Introducing Expected Information Gain</h3>
<p>In Bayesian experiment design <span class="citation" data-cites="rainforth2024modern">(<a href="#ref-rainforth2024modern" role="doc-biblioref">Rainforth et al. 2024</a>)</span>, a commonly used utility function is the information gain, where we are comparing the entropy of the distributions before and after observing an addition point. Assuming that our existing data set is denoted by <span class="math inline">\(\mathcal{D}\)</span> and the posterior distribution is <span class="math inline">\(p(\cdot | \mathcal{D})\)</span>. If we make an observation at <span class="math inline">\(x\)</span> and observe <span class="math inline">\(y\)</span>, our new data set will become <span class="math inline">\(\mathcal{D}^+ := \mathcal{D} \cup \{(x, y)\}\)</span>. This will then correspond to a new posterior <span class="math inline">\(p(\cdot | \mathcal{D}^+)\)</span>.</p>
<p>Given those, the <strong>information gain</strong> (IG) is given by:</p>
<p><span class="math display">\[
IG(x) = H(p(\cdot | \mathcal{D})) - H(p(\cdot | \mathcal{D}^+)).
\]</span></p>
<p>Consider our distribution is a Gaussian process (GP) with mean zero and kernel <span class="math inline">\(k\)</span>, and the posterior is the posterior predictive distribution of this GP on some finite set of test points <span class="math inline">\(x_*\)</span> with size <span class="math inline">\(m\)</span>. We also assume the current data set <span class="math inline">\(\mathcal{D} := \{(x_i, y_i)\}_{i=1}^{n}\)</span> is of size <span class="math inline">\(n\)</span> and the observations with additive, centered, independent Gaussian noise of variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>We will also use the following notations to denote the various Gram matrices using kernel <span class="math inline">\(k\)</span></p>
<ul>
<li><span class="math inline">\(K = k(X,X)\)</span>, size <span class="math inline">\(n \times n\)</span>.</li>
<li><span class="math inline">\(K_* = k(X, x_*)\)</span>, size <span class="math inline">\(n \times m\)</span>.</li>
<li><span class="math inline">\(K_{**} = k(x_*, x_*)\)</span>, size <span class="math inline">\(m \times m\)</span>.</li>
</ul>
<p>The posterior is therefore (see <a href="https://shusheng3927.github.io/posts/2024-10-13-basic-GP-regression-formula/">here</a> for a detailed derivation)</p>
<p><span class="math display">\[
\begin{split}
p(y^* | x^*, \mathcal{D}, \sigma^2) &amp;\sim \mathcal{N}(\mu_{y^*|\mathcal{D}}, \Sigma_{y^*|\mathcal{D}}) \\
&amp;\mu_{y^*|\mathcal{D}} = K_*^T (K + \sigma^2 I_n)^{-1} y\\
&amp;\Sigma_{y^*|\mathcal{D}} = K_{**} - K_*^T (K + \sigma^2 I_n)^{-1} K_*.
\end{split}
\]</span></p>
<p>After adding a new observation at <span class="math inline">\(x\)</span>, we will have an updated dataset <span class="math inline">\(\mathcal{D}^+\)</span> with <span class="math inline">\(X^+ = X \cup \{x\}\)</span> and have an updated posterior using the following Gram matrices</p>
<ul>
<li><span class="math inline">\(K^+ = k(X^+,X^+)\)</span>, size <span class="math inline">\((n+1) \times (n+1)\)</span>.</li>
<li><span class="math inline">\(K_*^+ = k(X^+, x_*)\)</span>, size <span class="math inline">\((n+1) \times m\)</span>.</li>
<li><span class="math inline">\(K_{**}^+ = K_{**} = k(x_*, x_*)\)</span>, size <span class="math inline">\(m \times m\)</span>.</li>
</ul>
<p>So, the updated posterior’s covariance matrix is</p>
<p><span class="math display">\[
\Sigma_{y^*|\mathcal{D}^+} = K_{**}^+ - K_*^{+T} (K^+ + \sigma^2 I_{n+1})^{-1} K_*^+
\]</span></p>
<p>Thus, the information gain can be written as</p>
<p><span class="math display">\[
IG(x) = H(p(\cdot | \mathcal{D})) - H(p(\cdot | \mathcal{D}^+))
\]</span> where using the <a href="https://statproofbook.github.io/P/mvn-dent">definition of the entropy of multivariate Gaussian</a> yields</p>
<p><span class="math display">\[
\begin{split}
IG(x) &amp;= \frac{1}{2} \log \det \Sigma_{y^*|\mathcal{D}} - \frac{1}{2} \log \det \Sigma_{y^*|\mathcal{D}^+} \\
&amp;= \frac{1}{2} \log \det \Big( K_{**} - K_*^T (K + \delta^2 I_n)^{-1} K_* \Big) - \frac{1}{2} \log \det \Big( K_{**}^+ - K_*^{+T} (K^+ + \sigma^2 I_{n+1})^{-1} K_*^+\Big)
\end{split}
\]</span> Since <span class="math inline">\(IG(x)\)</span> is independent of <span class="math inline">\(y | x\)</span>, the acquisition function <strong>expected information gain</strong> (EIG) is therefore</p>
<p><span class="math display">\[
EIG(x) = \mathbb{E}_{y}[IG(x)] = IG(x)
\]</span> Furthermore, we can remove several terms when we do <span class="math inline">\(\arg\max_x\)</span> for the acquisition function optimisation, and get</p>
<p><span class="math display">\[
EIG(x) = - \log \det \Big( K_{**}^+ - K_*^{+T} (K^+ + \sigma^2 I_{n+1})^{-1} K_*^+\Big).
\]</span></p>
<p>In the current setup, the information gain is tractable due to nice properties of multivariate Gaussians and GP regression conjugacies. Albeit tractable, the immediate formulation of the expected information gain has undesirable computational costs which we will elaborate below. After a preliminary attempt to reformulate EIG in order to reduce the computation cost, we will present a different perspective of EIG using mutual information, which enables an EIG formulation with low computational costs.</p>
</section>
<section id="eig-reformualtion---a-first-attempt" class="level3">
<h3 class="anchored" data-anchor-id="eig-reformualtion---a-first-attempt">EIG Reformualtion - a first attempt</h3>
<p>We will consider the naive computation of the above <span class="math inline">\(EIG(x)\)</span> expression. One should note that in the active learning settings, we would often be in the scenarios where <span class="math inline">\(m &gt;&gt; n\)</span>. An improved approach of computing the same quantity is presented below, leveraging the matrix determinant lemma.</p>
<section id="naive-implementation" class="level4">
<h4 class="anchored" data-anchor-id="naive-implementation">Naive Implementation</h4>
<p>We wish to compute</p>
<p><span class="math display">\[
EIG(x) = - \log\det \Big( K_{**}^+ - K_*^{+T} (K^+ + \sigma^2 I_{n+1})^{-1} K_*^+\Big).
\]</span></p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 62%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Order</th>
<th>Expression</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\((K^+ + \delta^2 I_{n+1})^{-1}\)</span></td>
<td><span class="math inline">\(O((n+1)^3)\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\((K^+ + \delta^2 I_{n+1})^{-1} K_*^+\)</span></td>
<td><span class="math inline">\(O((n+1)^2 m)\)</span></td>
</tr>
<tr class="odd">
<td>3</td>
<td><span class="math inline">\(K_*^{+T} (K^+ + \delta^2 I_{n+1})^{-1}K_*^+\)</span></td>
<td><span class="math inline">\(O(m (n+1)^2)\)</span></td>
</tr>
<tr class="even">
<td>4</td>
<td><span class="math inline">\(K^+ - K_*^{+T} (K^+ + \delta^2 I_{n+1})^{-1} K_*^+\)</span></td>
<td><span class="math inline">\(O(m^2)\)</span></td>
</tr>
<tr class="odd">
<td>5</td>
<td><span class="math inline">\(-\log\det\big(K_{**}^+ - K_*^{+T} (K^+ + \delta^2 I_{n+1})^{-1} K_*^+ \big)\)</span></td>
<td><span class="math inline">\(O({\color{red}m^3})\)</span></td>
</tr>
</tbody>
</table>
<p>So the cost is</p>
<p><span class="math display">\[
O((n+1)^3 + (n+1)^2 m + m^2 (n+1) + m^2 + {\color{red}m^3}).
\]</span> We will need to compute the above quantity <span class="math inline">\(m\)</span> times for comparison <span class="math inline">\(\arg\max_x\)</span>, thus the full costs is</p>
<p><span class="math display">\[
O((n+1)^3m + (n+1)^2 m^2 + m^3 (n+1) + m^3 + {\color{red}m^4}).
\]</span></p>
</section>
<section id="nontrivial-implementation" class="level4">
<h4 class="anchored" data-anchor-id="nontrivial-implementation">Nontrivial Implementation</h4>
<p>We use the <a href="https://en.wikipedia.org/wiki/Matrix_determinant_lemma">matrix determinant identity</a>:</p>
<p><span class="math display">\[
\det(A + UWV^T) = \det(A) \det(W) \det(W + V^T A^{-1} U)
\]</span></p>
<p>where here</p>
<ul>
<li><span class="math inline">\(A = K_{**}^+\)</span></li>
<li><span class="math inline">\(U = -K_*^{+T}\)</span></li>
<li><span class="math inline">\(W = (K^+ + \sigma^2 I_{n+1})^{-1}\)</span></li>
<li><span class="math inline">\(V = K_*^+\)</span></li>
</ul>
<p>Thus, we wish to compute</p>
<p><span class="math display">\[
EIG(x) = -\log \left[ \det(K_{**}^+) \cdot 1/ \det(K^+ + \sigma^2 I_{n+1}) \cdot \det \big(K^+ + \sigma^2 I_{n+1}- K_*^+ (K_{**}^+)^{-1}K_*^{+T} \big) \right]
\]</span></p>
<p>Since <span class="math inline">\(K_{**}\)</span> is positive semi-definite, its determinant is always non-negative so we can ignore it in comparisons.</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 66%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Order</th>
<th>Expression</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(K_{**}^+ + \sigma^2 I_{n+1}\)</span></td>
<td><span class="math inline">\(O((n+1)^2)\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(\det(K^+ + \sigma^2 I_{n+1})\)</span></td>
<td><span class="math inline">\(O((n+1)^3)\)</span></td>
</tr>
<tr class="odd">
<td>3</td>
<td><span class="math inline">\((K_{**}^+)^{-1}\)</span></td>
<td><span class="math inline">\(O(m^3)\)</span>, reusable</td>
</tr>
<tr class="even">
<td>4</td>
<td><span class="math inline">\((K_{**}^+)^{-1}K_*^{+T}\)</span></td>
<td><span class="math inline">\(O(m^2(n+1))\)</span></td>
</tr>
<tr class="odd">
<td>5</td>
<td><span class="math inline">\(K_*^+ (K_{**}^+)^{-1}K_*^{+T}\)</span></td>
<td><span class="math inline">\(O(m(n+1)^2)\)</span></td>
</tr>
<tr class="even">
<td>6</td>
<td><span class="math inline">\((K^+ + \sigma^2 I_{n+1}) - K_*^+ (K_{**}^+)^{-1}K_*^{+T}\)</span></td>
<td><span class="math inline">\(O((n+1)^2)\)</span></td>
</tr>
<tr class="odd">
<td>7</td>
<td><span class="math inline">\(\det\big( (K^+ + \sigma^2 I_{n+1}) - K_*^+ (K_{**}^+)^{-1}K_*^{+T} \big)\)</span></td>
<td><span class="math inline">\(O((n+1)^3)\)</span></td>
</tr>
<tr class="even">
<td>8</td>
<td><span class="math inline">\(\log \left[ 1/ \det(K^+ + \sigma^2 I_{n+1}) \cdot \det \big(K^+ + \sigma^2 I_{n+1}- K_*^+ (K_{**}^+)^{-1}K_*^{+T} \big) \right]\)</span></td>
<td><span class="math inline">\(O(1)\)</span></td>
</tr>
</tbody>
</table>
<p>So the cost is <span class="math display">\[
O((n+1)^2 + (n+1)^3 + {\color{blue}m^3} + m^2(n+1) + m(n+1)^2).
\]</span></p>
<p>We will need to compute the above quantity <span class="math inline">\(m\)</span> times for comparison <span class="math inline">\(\arg\max_x\)</span>, thus the full costs is</p>
<p><span class="math display">\[
O((n+1)^2m + (n+1)^3m + {\color{blue}m^3} + m^3(n+1) + m^2(n+1)^2).
\]</span></p>
</section>
</section>
<section id="eig-reformualtion---a-second-attempt" class="level3">
<h3 class="anchored" data-anchor-id="eig-reformualtion---a-second-attempt">EIG Reformualtion - a second attempt</h3>
<section id="eig-over-n-observations" class="level4">
<h4 class="anchored" data-anchor-id="eig-over-n-observations">EIG over <span class="math inline">\(n\)</span> Observations</h4>
<p>Instead of the one-step EIG update (the difference in entropies between the posteriors with and without an additional observation), below we derive the EIG of the entirety of <span class="math inline">\(n\)</span> observations. This quantity could be used as the objective for non-myopic policies, such as the case of deep adaptive designs <span class="citation" data-cites="foster2021deep">(<a href="#ref-foster2021deep" role="doc-biblioref">Foster et al. 2021</a>)</span>.</p>
<p>Consider we have the prior (a GP with kernel <span class="math inline">\(k\)</span>) <span class="math inline">\(p(\cdot)\)</span> and we have <span class="math inline">\(n\)</span> observations <span class="math inline">\(\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n =: \{ (\boldsymbol{x}, \boldsymbol{y})\}\)</span> which yields the posterior <span class="math inline">\(p(\cdot | \mathcal{D})\)</span>, the information gain quantity of interest would be</p>
<p><span class="math display">\[
IG(\boldsymbol{x}) = H(p(\cdot)) - H(p(\cdot | \mathcal{D})) = MI(p(\cdot); \boldsymbol{y})
\]</span> where the last equality follows from the definition of <a href="https://en.wikipedia.org/wiki/Mutual_information">mutual information</a>.</p>
<p>Again, if we consider those GPs on a fixed, finite set of test points <span class="math inline">\(x_*\)</span> like before, we would be able to show the following:</p>
<p><span class="math display">\[
\begin{split}
IG(\boldsymbol{x}) &amp;= H(p(\cdot)) - H(p(\cdot | \mathcal{D})) \\
&amp;= \frac{1}{2} \log \det K_{**} - \frac{1}{2} \log \det \left[ K_{**} - K_*^T (K + \sigma^2 I_n)^{-1} K_*\right] \\
&amp;= - \frac{1}{2} \log \det \left[K_{**}^{-1}( K_{**} - K_*^T (K + \sigma^2 I_n)^{-1} K_*)\right] \\
&amp;= - \frac{1}{2} \log \det \left[I_m - K_{**}^{-1} K_*^T (K + \sigma^2 I_n)^{-1} K_*)\right] \\
\end{split}
\]</span> where, as before, we use the shorthand notations</p>
<ul>
<li><span class="math inline">\(K = k(X,X)\)</span>, size <span class="math inline">\(n \times n\)</span>.</li>
<li><span class="math inline">\(K_* = k(X, x_*)\)</span>, size <span class="math inline">\(n \times m\)</span>.</li>
<li><span class="math inline">\(K_{**} = k(x_*, x_*)\)</span>, size <span class="math inline">\(m \times m\)</span>.</li>
</ul>
</section>
<section id="low-cost-eig-formulation" class="level4">
<h4 class="anchored" data-anchor-id="low-cost-eig-formulation">Low Cost EIG Formulation</h4>
<p>The above computation is at least cubic in <span class="math inline">\(m\)</span> due to the determinant operation. In fact, using the symmetric property of the mutual information, we could obtain a much better expression.</p>
<p>Note that <span class="math display">\[MI(X; Y) = H(X) - H(X|Y) = H(Y) - H(Y|X).\]</span> We first denote the prior as <span class="math inline">\(f\)</span>, the observations <span class="math inline">\(\boldsymbol{y_A}\)</span> at locations <span class="math inline">\(\boldsymbol{x_A}\)</span> with observational noise <span class="math inline">\(\boldsymbol{\varepsilon}\)</span> so <span class="math inline">\(\boldsymbol{y_A} = f(\boldsymbol{x_A}) + \boldsymbol{\varepsilon}\)</span>.</p>
<p>The information gain from prior to posterior after observing <span class="math inline">\(\boldsymbol{y_A}\)</span> can be written as the mutual information</p>
<p><span class="math display">\[
IG(\boldsymbol{x_A}) = H(f) - H(f |\boldsymbol{y_A}) = MI(f; \boldsymbol{y_A}) = H(\boldsymbol{y_A}) - H(\boldsymbol{y_A} | f).
\]</span></p>
<p>Notice that since <span class="math inline">\(y_A = f(\boldsymbol{x_A}) + \boldsymbol{\varepsilon}\)</span>, it is a multivariate with covariance <span class="math inline">\(K(\boldsymbol{x_A}, \boldsymbol{x_A}) + \sigma^2 I\)</span>. In addition, <span class="math inline">\(\boldsymbol{y_A} | f\)</span> has covariance being just <span class="math inline">\(\sigma^2 I\)</span>. Therefore, we have</p>
<p><span class="math display">\[
\begin{split}
IG(\boldsymbol{x_A}) &amp;= H(\boldsymbol{y_A}) - H(\boldsymbol{y_A} | f) \\
&amp;= \log \det (K(\boldsymbol{x_A}, \boldsymbol{x_A}) + \sigma^2 I) - \log \det (\sigma^2 I) \\
&amp;= \log \det (I + \sigma^{-2} K(\boldsymbol{x_A}, \boldsymbol{x_A}))
\end{split}
\]</span></p>
<p>which is the expression used in Section 2.2 of <span class="citation" data-cites="srinivas2010gaussian">Srinivas et al. (<a href="#ref-srinivas2010gaussian" role="doc-biblioref">2010</a>)</span>, and is computationally cheap.</p>
<p>Using the same concept, we can rewrite the EIG of posteriors between <span class="math inline">\(\mathcal{D} = \{ (\boldsymbol{x_A}, \boldsymbol{y_A}) \}\)</span> and <span class="math inline">\(\mathcal{D}^+ = \{ (\boldsymbol{x_B}, \boldsymbol{y_B}) \}\)</span> (i.e.&nbsp;subject to one more observation). We have the information gain</p>
<p><span class="math display">\[
\begin{split}
IG(x) &amp;= H(f | \boldsymbol{y_A}) - H(f | \boldsymbol{y_B}) \\
&amp;= - H(f) + H(f | \boldsymbol{y_A}) + H(f) - H(f | \boldsymbol{y_B}) \\
&amp;= - [H(f) - H(f | \boldsymbol{y_A})] + [H(f) - H(f | \boldsymbol{y_B})] \\
&amp;= - [IG(\boldsymbol{x_A}) ] + [IG(\boldsymbol{x_B})] \\
&amp;= - \log \det (I + \sigma^{-2} K(\boldsymbol{x_A}, \boldsymbol{x_A})) + \log \det (I + \sigma^{-2} K(\boldsymbol{x_B}, \boldsymbol{x_B})).
\end{split}
\]</span></p>
<p>Notice that the first term is the same when comparing across different <span class="math inline">\(x\)</span>, thus can be omitted. This formulation’s cost is therefore</p>
<p><span class="math display">\[
O((n+1)^2 + (n+1)^3)
\]</span></p>
<p>for one-time computation and the overall cost for comparison <span class="math inline">\(\arg\max_x\)</span> is</p>
<p><span class="math display">\[
O(m(n+1)^2 + m(n+1)^3).
\]</span></p>
<p>One should note that similar rewriting of entropy-related objectives using the symmetry of mutual information also exist in the Bayesian optimization literature with the entropy search and the predictive entropy search (e.g. <span class="citation" data-cites="hernandez2014predictive">Hernández-Lobato, Hoffman, and Ghahramani (<a href="#ref-hernandez2014predictive" role="doc-biblioref">2014</a>)</span>).</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-foster2021deep" class="csl-entry" role="listitem">
Foster, Adam, Desi R Ivanova, Ilyas Malik, and Tom Rainforth. 2021. <span>“Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design.”</span> In <em>International Conference on Machine Learning</em>, 3384–95. PMLR.
</div>
<div id="ref-hernandez2014predictive" class="csl-entry" role="listitem">
Hernández-Lobato, José Miguel, Matthew W Hoffman, and Zoubin Ghahramani. 2014. <span>“Predictive Entropy Search for Efficient Global Optimization of Black-Box Functions.”</span> <em>Advances in Neural Information Processing Systems</em> 27.
</div>
<div id="ref-lindley1956measure" class="csl-entry" role="listitem">
Lindley, Dennis V. 1956. <span>“On a Measure of the Information Provided by an Experiment.”</span> <em>The Annals of Mathematical Statistics</em> 27 (4): 986–1005.
</div>
<div id="ref-rainforth2024modern" class="csl-entry" role="listitem">
Rainforth, Tom, Adam Foster, Desi R Ivanova, and Freddie Bickford Smith. 2024. <span>“Modern Bayesian Experimental Design.”</span> <em>Statistical Science</em> 39 (1): 100–114.
</div>
<div id="ref-srinivas2010gaussian" class="csl-entry" role="listitem">
Srinivas, Niranjan, Andreas Krause, Sham Kakade, and Matthias Seeger. 2010. <span>“Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design.”</span> In <em>Proceedings of the 27th International Conference on Machine Learning</em>, 1015–22. Omnipress.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>